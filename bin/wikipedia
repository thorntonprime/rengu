#!/usr/bin/python3

import sys
import unicodedata
import wptools

def normalize(input_str):
  ## Returns a NFKD normalized form of the input string
  nfkd_form = unicodedata.normalize('NFKD', input_str)
  return u"".join([c for c in nfkd_form if not unicodedata.combining(c)])

def wiki_page(title):

  page = wptools.page(normalize(title), silent=True, skip=['imageinfo'])
  try:
    page.get(timeout=5)
  except LookupError:
    page.data = { 'what': "_error lookup_" }
    return page
  except RecursionError:
    page.data = { 'what': "_error recusion_" }
    return page
  except:
    page.data = { 'what': "_error other_" }
    return page

  what = str(page.data.get('what', 'none')).strip()
  if what == 'Wikimedia disambiguation page':
    what = "disambiguate"

  if not 'label' in page.data:
    page.data = { 'label' : "_error no label_" }

  return page

if __name__ == '__main__':

  print("|| Title || Match ||")

  for title in [x.strip() for x in sys.stdin.readlines() ]:
     page = wiki_page(title)
     print("| %s | [%s](%s) |" % (title, page.data.get('label'), page.data.get('url', '')))

