#!/usr/bin/python3

import sys
import unicodedata
import wptools

def normalize(input_str):
  ## Returns a NFKD normalized form of the input string
  nfkd_form = unicodedata.normalize('NFKD', input_str)
  return u"".join([c for c in nfkd_form if not unicodedata.combining(c)])

def wiki_page(title):

  page = wptools.page(normalize(title), silent=True, skip=['imageinfo'])
  try:
    page.get(timeout=5)
  except LookupError:
    page.data = { 'what': "_error lookup_" }
    return page
  except RecursionError:
    page.data = { 'what': "_error recusion_" }
    return page
  except:
    page.data = { 'what': "_error other_" }
    return page

  if not 'label' in page.data:
    page.data = { 'label' : "_error no label_" }

  return page



def wiki_lookup():

  for title in [x.strip() for x in sys.stdin.readlines() ]:
     page = wiki_page(title)

     label = page.data.get("label")
     url = page.data.get("url", "")
     what = page.data.get("what", "NONE")
     if type(what) is tuple:
       what = ','.join(what)
     if what == 'Wikimedia disambiguation page':
       what = "_disambiguate_"


     print("[%s](%s) | %s | %s " % (label, url, what, title))

def alternate_names(name):

    from ftfy import fix_text
    import re

    # Return the name passed first
    yield name

    yield fix_text(name)

    # next remove all accents
    nfkd_form = unicodedata.normalize('NFKD', fix_text(name))
    yield u"".join([c for c in nfkd_form if not unicodedata.combining(c)])

    # Check for titles
    honorifics = [ "St ", "Saint ", "Abbot ", "Mrs  ", "Doctor ", "The ", "Sir " ]
    for h in honorifics:
        if re.search(h, name):
            yield name.replace(h, "").strip()
 

if __name__ == '__main__':

    wiki_lookup()
